"use strict";(self.webpackChunktu_cis_4398_docs_template=self.webpackChunktu_cis_4398_docs_template||[]).push([[3196],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var i=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},r=Object.keys(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=i.createContext({}),c=function(e){var t=i.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=c(e.components);return i.createElement(l.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},u=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=c(n),d=a,m=u["".concat(l,".").concat(d)]||u[d]||h[d]||r;return n?i.createElement(m,o(o({ref:t},p),{},{components:n})):i.createElement(m,o({ref:t},p))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,o=new Array(r);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,o[1]=s;for(var c=2;c<r;c++)o[c]=n[c];return i.createElement.apply(null,o)}return i.createElement.apply(null,n)}u.displayName="MDXCreateElement"},21317:function(e,t,n){n.r(t),n.d(t,{assets:function(){return p},contentTitle:function(){return l},default:function(){return d},frontMatter:function(){return s},metadata:function(){return c},toc:function(){return h}});var i=n(83117),a=n(80102),r=(n(67294),n(3905)),o=["components"],s={sidebar_position:1},l="System Overview",c={unversionedId:"requirements/system-overview",id:"requirements/system-overview",title:"System Overview",description:"Project Abstract",source:"@site/docs/requirements/system-overview.md",sourceDirName:"requirements",slug:"/requirements/system-overview",permalink:"/project-attendance-face-recognition/docs/requirements/system-overview",draft:!1,editUrl:"https://github.com/Capstone-Projects-2022-Fall/project-attendance-face-recognition/edit/main/documentation/docs/requirements/system-overview.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"docsSidebar",previous:{title:"Requirements Specification",permalink:"/project-attendance-face-recognition/docs/category/requirements-specification"},next:{title:"System Block Diagram",permalink:"/project-attendance-face-recognition/docs/requirements/system-block-diagram"}},p={},h=[{value:"Project Abstract",id:"project-abstract",level:2},{value:"High Level Requirement",id:"high-level-requirement",level:2},{value:"Conceptual Design",id:"conceptual-design",level:2},{value:"Scope of the Project",id:"scope-of-the-project",level:2}],u={toc:h};function d(e){var t=e.components,n=(0,a.Z)(e,o);return(0,r.kt)("wrapper",(0,i.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"system-overview"},"System Overview"),(0,r.kt)("h2",{id:"project-abstract"},"Project Abstract"),(0,r.kt)("p",null,"This document proposes a novel application of face recognition as a biometric technique to track the attendance of employees within a remote company, as well as students taking a course virtually. By utilizing built-in cameras that many mobile devices and laptops have nowadays, this application will identify and analyze each unique face within the span of the camera and match it with an image from the database. If the application does not identify the person, it will let the user (eg. boss, professor, etc.) know about it. The attendance report of everyone who was present will also be shown to the admin."),(0,r.kt)("p",null,"There will be two different views for the web application, the admin view and the take attendance view. The take attendance view will allow those within a specific organization to utilize their web camera to take attendance. They will only be able to access while the admin has a schedule set for a specific date and timeframe. This view will also include the ability to view attendance reports so that they may keep track of their own attendance. If they have trouble taking attendance, they will have option to fill out an issues form to alert their administrator. The admin view will contain the record of all the attendances taken, as well as any issues that users may have faced. The admin can approve or reject any issues that get presented to them. Additionally, the admin can set the schedule for taking attendance. This allows for attendance to only be taken when they so desire."),(0,r.kt)("h2",{id:"high-level-requirement"},"High Level Requirement"),(0,r.kt)("p",null,"This application is fully web-based and facial recognition will be developed using python libraries. There will be a database that contains images of every user within a specific work team or class (set the first time they use the application). The application will work by installing it to their specific organization applications or by itself. When a user opens the application, they'll be prompted to turn on and look at their camera in good lighting. The user will be matched against existing data within the dataset. If a user is recognized, their presence will be recorded. Otherwise, it gives them a few attempts to try again. Once the limited number of attempts is met, the user could report the issue to the admin."),(0,r.kt)("h2",{id:"conceptual-design"},"Conceptual Design"),(0,r.kt)("p",null,"The initial plan for developing this web-based application is by building the front-end using HTML, CSS, JavaScript, React and Django framework. The backend will be developed using the programming lanugage Python and will utilize libraries such as: OpenCV, Dlib, and Face Recognition package. A database (eg. MySQL) will be used to store the data of the users. Any operating system could be used as it is a web-based application. The camera built into a user's laptop or mobile device will be used to scan their face. We plan to integrate our web application with the Canvas platform."),(0,r.kt)("h2",{id:"scope-of-the-project"},"Scope of the Project"),(0,r.kt)("p",null,"We, the team members, are designing this project for both schools and companies to use face recognition for attendance. The project will require front end skills for web application development and back-end skills for face recognition (namely - Python and OpenCV). Some database knowledge will also be required. The project should be finished within 3 months or less. We also are fortunate to have individuals on the team with these required skills. Throughout the semester, we will have a weekly plan to manage the development of the application and ensure that deliverables meet the deadlines. The main limitation to this project is the need for good lighting while a user's face is in front of the camera. If there isn't good lighting, there may be issues within the application recognizing who the user is. Another limitation is the requirement of Canvas, as we initally plan to integrate this project with the Canvas platform."))}d.isMDXComponent=!0}}]);